{
 "metadata": {
  "name": "",
  "signature": "sha256:af01049b30128688645faa9210f04a2b16267eee2595ece0665dd5a8624e8c01"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime as dt\n",
      "import pylab\n",
      "import random\n",
      "import seaborn as sns\n",
      "from pandas import Series, DataFrame\n",
      "from sdipylib.url import cache_url # install using anaconda/bin/pip install sdipylib\n",
      "from IPython.core.display import HTML, Javascript\n",
      "from calendar import day_abbr, month_abbr\n",
      "\n",
      "%matplotlib inline\n",
      "pd.options.display.mpl_style = 'default'\n",
      "sns.set_palette(\"deep\", desat=.6)\n",
      "\n",
      "pd.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'0.13.1'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = cache_url('http://devtest.sandiegodata.org.s3.amazonaws.com/manifests/fc22cee6-acfa-4236-a6cb-e0d887eba178/211_service_calls.csv')\n",
      "service_call_data = pd.read_csv(fn, dtype =  {16: str, 26: str, 27: str, 29: str}, parse_dates=['create_time'])\n",
      "random.seed(42)\n",
      "random1000ksample = service_call_data.ix[sorted(random.sample(service_call_data.index, 1000))]\n",
      "random1000ksample.to_csv('1000k_211_service_calls.csv')\n",
      "print fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/kevin/Desktop/211sandiego-org-17-call_analysis/analysts/211_service_calls.csv\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Richness: Sparsity and Density"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nonnull_data_cols = service_call_data.count()\n",
      "n_nonnull_data = nonnull_data_cols.sum()\n",
      "n_service_calls = len(service_call_data)\n",
      "n_cells = n_service_calls*len(service_call_data.columns)\n",
      "data_completion_overall = (n_nonnull_data/float(n_cells))*100\n",
      "columns_and_data_completion_percentages = (nonnull_data_cols/float(n_service_calls))*100\n",
      "columns_and_data_completion_percentages.name = \"columns_and_data_completion_percentages\"\n",
      "print \"Overall data has {0}% of cells filled out\".format(data_completion_overall)\n",
      "print \"Completion Percentages of columns:\"\n",
      "print\n",
      "print columns_and_data_completion_percentages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is scant information in this dataset about call status, income declined, and reasons for unmet needs,<br />\n",
      "but otherwise the dataset is rich enough to work with."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature Engineering the Data for Predictive Tasks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to determine which columns are features and which are not, as well as make new columns based on a combination and transformation of the original data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_unique_values_counts = map(lambda col_name : len(service_call_data[col_name].unique()), service_call_data.columns)\n",
      "unique_values = map(lambda col_name : set(service_call_data[col_name].unique()), service_call_data.columns)\n",
      "columns_and_num_unique_values = pd.Series(n_unique_values_counts, index=service_call_data.columns, name=\"num_unique_values\")\n",
      "columns_and_unique_values = pd.Series(unique_values, index=service_call_data.columns, name=\"unique_values\")\n",
      "columns_completion_and_unique_values_df = pd.concat([columns_and_data_completion_percentages, columns_and_num_unique_values, columns_and_unique_values], axis=1)\n",
      "columns_completion_and_unique_values_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'service_call_data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-e482389f6781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_unique_values_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice_call_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mservice_call_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0munique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice_call_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mservice_call_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolumns_and_num_unique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_unique_values_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_call_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"num_unique_values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolumns_and_unique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice_call_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unique_values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcolumns_completion_and_unique_values_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns_and_data_completion_percentages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_and_num_unique_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_and_unique_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'service_call_data' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SPARSE_FEATURES =  [\"call_stat\", \"caller_age\", \"hshld_size_code\"]\n",
      "SPARSE_FEATURES += [\"hshld_pct_fpl_code\", \"income_declined\", \"zip_code\", \"need_reason_unmet\"]\n",
      "\n",
      "NONFEATURES = [\"id\", \"restrictions\", \"create_time\", \"client_id\", \"zip\", \"zip_code\"]\n",
      "\n",
      "RATIO_DATA_COLUMNS = [\"create_time\", \"caller_age\", \"hshld_size\", \"hshld_income\", \"hshld_pct_fpl\"]\n",
      "INTERVAL_DATA_COLUMNS = [\"id\", \"client_id\"]\n",
      "ORDINAL_DATA_COLUMNS = [\"age_goups\"] # \"age_goups\" should be spelled age_groups\n",
      "NOMINAL_DATA_COLUMNS =  [\"call_stat\", \"call_type\", \"restrictions\", \"queue\", \"relationship\", \"called_before\"]\n",
      "NOMINAL_DATA_COLUMNS += [\"preg_lt6\", \"child_lt6\", \"ethnicity\", \"race\", \"language\", \"hshld_size_code\"]\n",
      "NOMINAL_DATA_COLUMNS += [\"income_source\", \"hshld_pct_fpl_code\", \"income_declined\", \"zip\", \"zip_code\"]\n",
      "NOMINAL_DATA_COLUMNS += [\"need_tax_code\", \"need_tax_cat\", \"need_unmet\", \"need_reason_unmet\", \"ref_agency\", \"ref_name\"]\n",
      "NOMINAL_DATA_COLUMNS += [\"hshld_disabled\", \"gender\", \"how_hear\", \"have_ins\", \"ins_type\"]\n",
      "    \n",
      "unique_values_as_str = map(str, service_call_data.age_goups.unique())\n",
      "nonnumber_strings = filter(lambda uvas : uvas[0] not in \"0123456789\", unique_values_as_str)\n",
      "valid_age_group_strings = set(unique_values_as_str) - set(nonnumber_strings)\n",
      "age_groups_sorted  = [\"Under 5 years\"]\n",
      "age_groups_sorted += sorted(valid_age_group_strings, key=lambda age_group_str : int(age_group_str.split()[0][:3]))\n",
      "age_groups_sorted += [\"Declined to State\"]    \n",
      "\n",
      "ORDERING = dict([(col_name, None) for col_name in ORDINAL_DATA_COLUMNS])\n",
      "ORDERING[\"age_goups\"] = age_groups_sorted"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# arbitrary rule of thumb values for different visualization methods\n",
      "MAX_NUM_CATEGORIES_TO_USE_PIE_CHART = 3\n",
      "MAX_NUM_CATEGORIES_TO_USE_BAR_CHART = 100\n",
      "MAX_NUM_CATEGORIES_TO_USE_HISTOGRAM = 24\n",
      "\n",
      "def double_check_column_name_exists(col_name):\n",
      "    assert col_name in service_call_data.columns, \"No such column '{0}' found in dataframe\".format(col_name)\n",
      "    \n",
      "def prepare_title_string_as_column_completion_info(col_name):\n",
      "    unique_values = filter(lambda v : str(v) != 'nan', service_call_data[col_name].unique())\n",
      "    n_unique_values = len(unique_values)\n",
      "    n_total_records = len(service_call_data)\n",
      "    n_nonnull_data = service_call_data[col_name].count()\n",
      "    \n",
      "    col_type = \"\"\n",
      "    if col_name in NOMINAL_DATA_COLUMNS:    col_type = \"Nominal\"\n",
      "    elif col_name in ORDINAL_DATA_COLUMNS:  col_type = \"Ordinal\"\n",
      "    elif col_name in INTERVAL_DATA_COLUMNS: col_type =\"Interval\"\n",
      "    elif col_name in RATIO_DATA_COLUMNS:    col_type = \"Ratio\"\n",
      "        \n",
      "    return '{0} Labeled \"{1}\" Values (={2}% of {3} labeled and non-labeled values)\\n{4} Unique {5} Values\\n'.format(n_nonnull_data, col_name,\n",
      "                                                                                    100.0*n_nonnull_data/n_total_records,\n",
      "                                                                                    n_total_records, n_unique_values, col_type)\n",
      "def draw_pie_chart(col_name, save=False):\n",
      "    double_check_column_name_exists(col_name)\n",
      "    \n",
      "    unique_values = service_call_data[col_name].unique()\n",
      "    nonnan_unique_values = filter(lambda v : str(v) != 'nan', unique_values)\n",
      "    nonnan_unique_values_counts = service_call_data[col_name].value_counts()[nonnan_unique_values]\n",
      "    \n",
      "    plt.figure(figsize=(7,7))\n",
      "    plt.title(prepare_title_string_as_column_completion_info(col_name))\n",
      "    plt.pie(nonnan_unique_values_counts,\n",
      "            colors=('c', 'm', 'y')[:len(nonnan_unique_values)],\n",
      "            labels=[\"%s = %d\" % (v, int(c)) for (v, c) in zip(nonnan_unique_values, nonnan_unique_values_counts)],\n",
      "            pctdistance=0.6,  autopct='%1.1f%%', startangle=90);\n",
      "    \n",
      "    if save: plt.savefig(col_name + \".png\", format=\"png\")\n",
      "    plt.show()\n",
      "    \n",
      "def draw_bar_chart(col_name, save=False):\n",
      "    double_check_column_name_exists(col_name)\n",
      "\n",
      "    nonnan_unique_values_counts = service_call_data[col_name].value_counts()\n",
      "    n_nonnan_unique_values = len(nonnan_unique_values_counts)\n",
      "    \n",
      "    if (col_name in ORDINAL_DATA_COLUMNS):\n",
      "        ordered_index = ORDERING[col_name]\n",
      "    else: # go by ascending value counts\n",
      "        ordered_index = nonnan_unique_values_counts.index\n",
      "        \n",
      "    if len(ordered_index) > MAX_NUM_CATEGORIES_TO_USE_HISTOGRAM:\n",
      "        ordered_index = ordered_index[:MAX_NUM_CATEGORIES_TO_USE_HISTOGRAM]\n",
      "            \n",
      "    ax = nonnan_unique_values_counts[reversed(ordered_index)].plot(kind='barh',\n",
      "                                                                   figsize=(8, min(max(4, np.ceil(n_nonnan_unique_values/4.0)), 24)),\n",
      "                                                                   title=prepare_title_string_as_column_completion_info(col_name)+\"\\n\")\n",
      "    ax.tick_params(labeltop=True)\n",
      "    ax.set_xlabel(\"Frequency\")\n",
      "\n",
      "    # annotate bar counts\n",
      "    for x,y in zip(range(n_nonnan_unique_values), nonnan_unique_values_counts[reversed(ordered_index)].values):\n",
      "        (xlim_min, xlim_max) = ax.get_xlim()\n",
      "        \n",
      "        if y > xlim_max*0.9:\n",
      "            ax.annotate(str(y),xy=(y*.9,x+.5), color=\"white\")\n",
      "        else:\n",
      "            ax.annotate(str(y),xy=(y,x+.5), color=\"black\")\n",
      "    \n",
      "    # show a scale of percentage proportions on right y-axis\n",
      "    total_count = sum(nonnan_unique_values_counts[reversed(ordered_index)].values)\n",
      "    percentage_proportions = (100.0*nonnan_unique_values_counts[reversed(ordered_index)].values) / total_count\n",
      "    percentage_proportions = map(lambda p : \"%.2f%%\" % p, percentage_proportions)\n",
      "    for_right_yaxis = ax.twinx()\n",
      "    for_right_yaxis.set_yticks(ax.get_yticks())\n",
      "    for_right_yaxis.set_yticklabels(percentage_proportions)\n",
      "    for_right_yaxis.set_ylim(ax.get_ylim())\n",
      "    for_right_yaxis.grid(False)\n",
      "        \n",
      "    if save: plt.savefig(col_name + \".png\", format=\"png\")\n",
      "    plt.show()\n",
      "    \n",
      "def draw_histogram(col_name, save=False):\n",
      "    double_check_column_name_exists(col_name)\n",
      "    \n",
      "    # http://stackoverflow.com/questions/13129618/histogram-values-of-a-pandas-series\n",
      "    \n",
      "    vcs = service_call_data[col_name].value_counts()\n",
      "    nonnan_bin_labels = vcs.index\n",
      "    \n",
      "    imaginary_rightmost_label = max(nonnan_bin_labels)+1\n",
      "    vcs[imaginary_rightmost_label] = 0\n",
      "    \n",
      "    nonnan_values = service_call_data[col_name].values[~np.isnan(service_call_data[col_name].values)]\n",
      "\n",
      "    plt.hist(nonnan_values, bins=sorted(vcs.index))\n",
      "    plt.title(prepare_title_string_as_column_completion_info(col_name))\n",
      "    ca = plt.gca()\n",
      "    ca.set_xlim([min(ca.get_xlim()), max(vcs.index)])\n",
      "    ca.set_ylabel(\"Frequency\")\n",
      "    \n",
      "    # annotate bin counts\n",
      "    total_counts = sum(vcs.values)\n",
      "    \n",
      "    for x in nonnan_bin_labels:\n",
      "        freq = vcs[x]\n",
      "        rel_freq = 100.0*freq/total_counts\n",
      "        plt.gca().annotate(str(\"%.2f%%\" % (rel_freq)), xy=(x,freq))\n",
      "    \n",
      "    if save: plt.savefig(col_name + \".png\", format=\"png\")\n",
      "    plt.show()\n",
      "\n",
      "def draw_boxplot(col_name, save=False):\n",
      "    double_check_column_name_exists(col_name)\n",
      "    \n",
      "    # http://stackoverflow.com/questions/23349626/getting-data-of-a-box-plot-matplotlib\n",
      "    # http://stackoverflow.com/questions/18861075/overlaying-the-numeric-value-of-median-variance-in-boxplots\n",
      "    nonnan_values = service_call_data[col_name].values[~np.isnan(service_call_data[col_name].values)]\n",
      "    sns.boxplot(nonnan_values, names=[\"\"], sym=\"\", vert=False, widths=.2)\n",
      "    \n",
      "    plt.gca().set_title(prepare_title_string_as_column_completion_info(col_name))\n",
      "    plt.gca().set_xlabel(\"numeric values\")\n",
      "    \n",
      "    if save: plt.savefig(col_name + \".png\", format=\"png\")\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns_with_too_many_categories = []\n",
      "\n",
      "for col_name in NOMINAL_DATA_COLUMNS + ORDINAL_DATA_COLUMNS + INTERVAL_DATA_COLUMNS + RATIO_DATA_COLUMNS:\n",
      "    if col_name in NONFEATURES:\n",
      "        continue\n",
      "        \n",
      "    unique_values = service_call_data[col_name].unique()\n",
      "    nonnan_unique_values = filter(lambda v : str(v) != 'nan', unique_values)\n",
      "    \n",
      "    if len(nonnan_unique_values) <= MAX_NUM_CATEGORIES_TO_USE_PIE_CHART and col_name in NOMINAL_DATA_COLUMNS:\n",
      "        draw_pie_chart(col_name)\n",
      "    elif len(nonnan_unique_values) <= MAX_NUM_CATEGORIES_TO_USE_BAR_CHART and ((col_name in NOMINAL_DATA_COLUMNS) or\n",
      "                                                                               (col_name in ORDINAL_DATA_COLUMNS)):\n",
      "        draw_bar_chart(col_name)\n",
      "    elif len(nonnan_unique_values) <= MAX_NUM_CATEGORIES_TO_USE_HISTOGRAM and ((col_name in INTERVAL_DATA_COLUMNS) or\n",
      "                                                                               (col_name in RATIO_DATA_COLUMNS)):\n",
      "        draw_histogram(col_name)\n",
      "    elif (col_name in INTERVAL_DATA_COLUMNS) or (col_name in RATIO_DATA_COLUMNS):\n",
      "        draw_boxplot(col_name)\n",
      "    else: # (col_name in NOMINAL_DATA_COLUMNS) or (col_name in ORDINAL_DATA_COLUMNS)\n",
      "        columns_with_too_many_categories.append(col_name)\n",
      "        \n",
      "for col_name in columns_with_too_many_categories:\n",
      "    print \"The column '{0}' has too many categories\".format(col_name)\n",
      "    draw_bar_chart(col_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}